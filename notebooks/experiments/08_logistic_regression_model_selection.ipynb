{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879cbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Step 2: Set up the MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://ec2-98-93-17-21.compute-1.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://sau-s3-mlflow-bucket/309540500998410326', creation_time=1763854853571, experiment_id='309540500998410326', last_update_time=1763854853571, lifecycle_stage='active', name='05 - Model Selection & Basic Hyperparameter Tuning', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "mlflow.set_experiment(\"05 - Model Selection & Basic Hyperparameter Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SAURABH\\spring 2024\\MLOps Project\\CreatorInsight AI Platform\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36607, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    '../../data/processed/reddit_clean_final.csv',\n",
    "    keep_default_na=False,\n",
    "    na_filter=False\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe98c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SAURABH\\spring 2024\\MLOps Project\\CreatorInsight AI Platform\\.venv\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "[I 2025-11-23 19:30:41,676] A new study created in memory with name: no-name-83b7c0af-9323-4d74-b50f-f9972e854caf\n",
      "[I 2025-11-23 19:30:46,208] Trial 0 finished with value: 0.7710651828298887 and parameters: {'C': 5.09586170628677, 'penalty': 'l1'}. Best is trial 0 with value: 0.7710651828298887.\n",
      "[I 2025-11-23 19:30:46,985] Trial 1 finished with value: 0.3333333333333333 and parameters: {'C': 0.0002025712600214876, 'penalty': 'l1'}. Best is trial 0 with value: 0.7710651828298887.\n",
      "[I 2025-11-23 19:30:49,502] Trial 2 finished with value: 0.7608903020667727 and parameters: {'C': 0.3007294882430228, 'penalty': 'l1'}. Best is trial 0 with value: 0.7710651828298887.\n",
      "[I 2025-11-23 19:30:50,830] Trial 3 finished with value: 0.5910969793322735 and parameters: {'C': 0.018310713372210144, 'penalty': 'l1'}. Best is trial 0 with value: 0.7710651828298887.\n",
      "[I 2025-11-23 19:30:51,538] Trial 4 finished with value: 0.3333333333333333 and parameters: {'C': 0.0007702585694922859, 'penalty': 'l1'}. Best is trial 0 with value: 0.7710651828298887.\n",
      "2025/11/23 19:31:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/23 19:31:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "d:\\SAURABH\\spring 2024\\MLOps Project\\CreatorInsight AI Platform\\.venv\\lib\\site-packages\\boto3\\compat.py:84: PythonDeprecationWarning: Boto3 will no longer support Python 3.9 starting April 29, 2026. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.10 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LogisticRegression_SMOTE_TFIDF_Bigrams at: http://ec2-98-93-17-21.compute-1.amazonaws.com:5000/#/experiments/309540500998410326/runs/d4cc2e7c58774fa0867ba083060a31db\n",
      "üß™ View experiment at: http://ec2-98-93-17-21.compute-1.amazonaws.com:5000/#/experiments/309540500998410326\n"
     ]
    }
   ],
   "source": [
    "# Step 1: (Optional) Remapping - skipped since not strictly needed for Logistic Regression\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Step 3: TF-IDF vectorizer setup\n",
    "ngram_range = (1, 2)  # Bigram\n",
    "max_features = 1000  # Set max_features to 1000\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X = vectorizer.fit_transform(df['clean_comment'])\n",
    "y = df['category']\n",
    "\n",
    "# Step 4: Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for Logistic Regression\n",
    "def objective_logreg(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "\n",
    "    # LogisticRegression model setup with balanced class weight\n",
    "    model = LogisticRegression(C=C, penalty=penalty, solver='liblinear', random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for Logistic Regression, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_logreg, n_trials=5)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], solver='liblinear', random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"LogisticRegression\"\n",
    "    log_mlflow(\"LogisticRegression\", best_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Run the experiment for Logistic Regression\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268605f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
